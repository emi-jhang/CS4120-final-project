{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2665e81d-9bd6-42d9-a049-c9413cdbb644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/oliviagao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     /Users/oliviagao/nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import cmudict\n",
    "\n",
    "# Download the CMU Pronouncing Dictionary for syllable counting\n",
    "nltk.download('cmudict')\n",
    "d = cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "386ebb78-fc05-472a-b017-35c3ad69aa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_data = pd.read_csv('../WCL_data/lexicon.csv')\n",
    "lexicon_ann = pd.read_csv('../WCL_data/lexicon_annotations.csv')\n",
    "\n",
    "wikipedia_train = pd.read_csv('../CWID_train/Wikipedia_Train.csv')\n",
    "wikipedia_dev = pd.read_csv('../CWID_train/Wikipedia_Dev.csv')\n",
    "wikipedia_test = pd.read_csv('../CWID_test/Wikipedia_Test.csv')\n",
    "news_train = pd.read_csv('../CWID_train/News_Train.csv')\n",
    "news_dev = pd.read_csv('../CWID_train/News_Dev.csv')\n",
    "news_test = pd.read_csv('../CWID_test/News_Test.csv')\n",
    "\n",
    "coca_df = pd.read_csv('../COCA/COCA_tokens.csv')\n",
    "# Convert words to lowercase for uniformity\n",
    "coca_df['Token'] = coca_df['Token'].str.lower()\n",
    "\n",
    "# Remove any non-alphabetic characters \n",
    "coca_df['Token'] = coca_df['Token'].str.replace(r'[^a-zA-Z]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "95478723-b23b-40b5-bc53-3849c49e739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Token           DocuScope Category   Count  Document Count  \\\n",
      "0      or  ReaderDirectedMetadiscourse  431525           40847   \n",
      "1     but  ReaderDirectedMetadiscourse  282210           38696   \n",
      "2     and                    Reasoning  215145           29204   \n",
      "3  people               CharacterTypes  206259           32557   \n",
      "4    more        InformationComparison  145672           35039   \n",
      "\n",
      "   Frequency (per mil. tokens)  % of Documents  Word Length  Syllable Count  \n",
      "0                      2425.94           95.62            2             1.0  \n",
      "1                      1586.52           90.58            3             1.0  \n",
      "2                      1209.50           68.36            3             1.0  \n",
      "3                      1159.54           76.21            6             2.0  \n",
      "4                       818.94           82.02            4             1.0  \n"
     ]
    }
   ],
   "source": [
    "# Define a frequency threshold to label words as simple or complex\n",
    "FREQUENCY_THRESHOLD = 0.87  # Adjust this threshold based on experimentation\n",
    "\n",
    "def syllable_count(word):\n",
    "    \"\"\"Return the syllable count for a word.\"\"\"\n",
    "    word = word.lower()\n",
    "    if word in d:\n",
    "        return max([len(list(y for y in x if y[-1].isdigit())) for x in d[word]])  # Get the max syllables\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "coca_df.drop([\"DocuScope Category\", \"Document Count\", \"% of Documents\"], axis=1, errors=\"ignore\")\n",
    "coca_df[\"Word Length\"] = coca_df[\"Token\"].apply(len)\n",
    "coca_df[\"Syllable Count\"] = coca_df[\"Token\"].apply(syllable_count)\n",
    "coca_df[\"Syllable Count\"] = coca_df[\"Syllable Count\"].fillna(coca_df[\"Syllable Count\"].mean())\n",
    "print(coca_df.head())\n",
    "\n",
    "# Define complexity label based on frequency, syllable count, and word length\n",
    "# Complexity is 1 (complex) if frequency is below threshold, word length is long, or syllables are high.\n",
    "# Complexity is 0 (simple) if frequency is above threshold and the word is shorter/simpler\n",
    "coca_df[\"Complexity\"] = (\n",
    "    (coca_df[\"Frequency (per mil. tokens)\"] < FREQUENCY_THRESHOLD) |   # Median frequency\n",
    "    (coca_df[\"Syllable Count\"] > 2.7408510638297874) |  # Median syllable count\n",
    "    (coca_df[\"Word Length\"] > 9)       # Median word length\n",
    ").astype(int)\n",
    "\n",
    "# Prepare the features (X) and target (y)\n",
    "X = coca_df[['Word Length', 'Syllable Count', 'Frequency (per mil. tokens)']]\n",
    "y = coca_df['Complexity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6092653a-12a7-48b0-b7ff-07d92484f77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1434\n",
      "           1       1.00      1.00      1.00      4236\n",
      "\n",
      "    accuracy                           1.00      5670\n",
      "   macro avg       1.00      1.00      1.00      5670\n",
      "weighted avg       1.00      1.00      1.00      5670\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Returns a 0 if simple, 1 if complex\n",
    "def predict_complexity(word):\n",
    "    # Fetch the row corresponding to the word from the DataFrame\n",
    "    word_row = coca_df[coca_df['Token'] == word]\n",
    "    \n",
    "    # If the word is not in the DataFrame, use default values\n",
    "    if word_row.empty:\n",
    "        # Use the average values for missing word\n",
    "        word_length = len(word)  # This is computed directly from the word\n",
    "        syllables = syllable_count(word)  # Use the mean syllable count from the DataFrame\n",
    "        word_frequency = coca_df['Frequency (per mil. tokens)'].median()  # Use the mean frequency from the DataFrame\n",
    "    else:\n",
    "        # Extract the values for 'Word Length', 'Syllable Count', and 'Frequency (per mil. tokens)' from the row\n",
    "        word_length = len(word)  # This is computed directly from the word\n",
    "        syllables = word_row['Syllable Count'].values[0]  # Extract syllable count from the dataset\n",
    "        word_frequency = word_row['Frequency (per mil. tokens)'].values[0]  # Extract frequency from the dataset\n",
    "    \n",
    "    # Construct the feature DataFrame as done during training\n",
    "    features_df = pd.DataFrame([[word_length, syllables, word_frequency]], \n",
    "                               columns=['Word Length', 'Syllable Count', 'Frequency (per mil. tokens)'])\n",
    "    \n",
    "    # Get the model's prediction\n",
    "    prediction = rf_classifier.predict(features_df)\n",
    "    \n",
    "    # Return the result\n",
    "    return prediction[0]\n",
    "\n",
    "# Test the function with some example words\n",
    "print(predict_complexity(\"dog\"))\n",
    "print(predict_complexity(\"but\"))\n",
    "print(predict_complexity(\"hello\"))\n",
    "print(predict_complexity(\"comprehensive\"))\n",
    "print(predict_complexity(\"multifarious\"))\n",
    "print(predict_complexity(\"techniques\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1467c5de-5c66-4e66-be67-daba33d5a674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: This is a simple sentence.\n",
      "Simplified Sentence: this is a simple sentence .\n",
      "considered\n",
      "Original Sentence: Although she was considered smart, she failed all her exams.\n",
      "Simplified Sentence: although she was considered smart , she failed all her exams .\n",
      "anachronism\n",
      "Original Sentence: Anachronism\n",
      "Simplified Sentence: anachronism\n"
     ]
    }
   ],
   "source": [
    "# Set threshold for complexity\n",
    "COMPLEXITY_THRESHOLD = 3\n",
    "\n",
    "def is_complex(word, lexicon_data, threshold=COMPLEXITY_THRESHOLD):\n",
    "    \"\"\"Check if a word is complex based on the lexicon or using COCA and a Random Forest Classifier.\"\"\"\n",
    "    # First check in the lexicon\n",
    "    entry = lexicon_data[lexicon_data['word'] == word]\n",
    "\n",
    "    # If the word is found in the lexicon\n",
    "    if not entry.empty:\n",
    "        rating = entry['rating'].values[0] # Get the complexity rating of the word\n",
    "        return rating >= threshold # Return True if the word's complexity rating is greater than or equal to the threshold\n",
    "    \n",
    "    # If the word is not in the lexicon, estimate its complexity using COCA and Random Forest\n",
    "    predicted_complexity = predict_complexity(word) # Predict complexity using the Random Forest model\n",
    "\n",
    "    return True if predicted_complexity == 1 else False\n",
    "\n",
    "def simplify_sentence(sentence, lexicon_data):\n",
    "    \"\"\"Simplify a sentence by replacing complex words with simpler synonyms.\"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    simplified_sentence = []\n",
    "    \n",
    "    for token in doc:\n",
    "        word = token.text.lower()\n",
    "        \n",
    "        # Check if the word is complex and replace with simpler synonym\n",
    "        if is_complex(word, lexicon_data):\n",
    "            print(word)\n",
    "            # TODO: REPLACE WORD\n",
    "            simple_word = word\n",
    "            \n",
    "            simplified_sentence.append(simple_word)\n",
    "        else:\n",
    "            simplified_sentence.append(word)\n",
    "    \n",
    "    return \" \".join(simplified_sentence)\n",
    "\n",
    "sentences = [\"This is a simple sentence.\", \"Although she was considered smart, she failed all her exams.\", \"Anachronism\"]\n",
    "for sentence in sentences:\n",
    "    simplified_sentence = simplify_sentence(sentence, lexicon_data)\n",
    "\n",
    "    print(\"Original Sentence:\", sentence)\n",
    "    print(\"Simplified Sentence:\", simplified_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba8f32-2802-4f8f-9908-9ac1d7b7fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing complex words with simpler ones\n",
    "\n",
    "# Load  NLTK data and SpaCy model\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def find_simpler_synonym(word):\n",
    "    \"\"\"\n",
    "    Find the simplest synonym for a given word using WordNet.\n",
    "    Simplicity is determined based on the length of the synonym.\n",
    "    \"\"\"\n",
    "    synonyms = wordnet.synsets(word)\n",
    "    if not synonyms:\n",
    "        return word  # Return the original word if no synonyms are found\n",
    "\n",
    "    # Extract the lemmas (unique words) for all synonyms\n",
    "    lemmas = set(lemma.name() for syn in synonyms for lemma in syn.lemmas())\n",
    "\n",
    "    # Sort lemmas by length to find the simplest synonym\n",
    "    simpler_synonym = min(lemmas, key=len, default=word)\n",
    "\n",
    "    # Replace underscores with spaces for readability\n",
    "    return simpler_synonym.replace('_', ' ') if simpler_synonym != word else word\n",
    "\n",
    "def is_complex(word, lexicon_data, coca_df=None, rf_classifier=None, threshold=3):\n",
    "    \"\"\"\n",
    "    Check if a word is complex using:\n",
    "    1. Lexicon data \n",
    "    2. COCA dataset and Random Forest Classifier as fallback.\n",
    "    \"\"\"\n",
    "    # Check the lexicon first\n",
    "    entry = lexicon_data[lexicon_data[\"word\"] == word]\n",
    "    if not entry.empty:\n",
    "        return entry[\"rating\"].values[0] >= threshold\n",
    "\n",
    "    # Fallback: Use Random Forest Classifier with COCA features\n",
    "    if coca_df is not None and rf_classifier is not None:\n",
    "        coca_entry = coca_df[coca_df[\"Token\"] == word]\n",
    "        if not coca_entry.empty:\n",
    "            # Prepare features for the classifier\n",
    "            features = coca_entry[[\"Word Length\", \"Syllable Count\", \"Frequency (per mil. tokens)\"]]\n",
    "            return rf_classifier.predict(features)[0] == 1\n",
    "\n",
    "    # Default to not complex if no data is available\n",
    "    return False\n",
    "\n",
    "\n",
    "def simplify_sentence(sentence, lexicon_data=None, threshold=3):\n",
    "    \"\"\"\n",
    "    Simplify a sentence by replacing complex words with simpler synonyms.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    simplified_sentence = []\n",
    "\n",
    "    for token in doc:\n",
    "        word = token.text\n",
    "        # Check if the word is complex\n",
    "        if is_complex(word.lower(), lexicon_data, threshold):\n",
    "            # Replace with a simpler synonym\n",
    "            simple_word = find_simpler_synonym(word)\n",
    "            simplified_sentence.append(simple_word)\n",
    "        else:\n",
    "            simplified_sentence.append(word)\n",
    "\n",
    "    return \" \".join(simplified_sentence)\n",
    "\n",
    "# test usage\n",
    "test_sentences = [\n",
    "    \"This is a simple sentence.\",\n",
    "    \"Although she was considered smart, she failed all her exams.\",\n",
    "    \"Anachronism in historical contexts can be confusing.\"\n",
    "]\n",
    "\n",
    "# Dummy lexicon data for testing\n",
    "\n",
    "#lexicon_data = pd.DataFrame({\n",
    "#    \"word\": [\"anachronism\", \"considered\", \"confusing\"],\n",
    "#    \"rating\": [5, 4, 4]\n",
    "#})\n",
    "\n",
    "# Simplify each sentence\n",
    "for sentence in test_sentences:\n",
    "    print(\"Original:\", sentence)\n",
    "    simplified = simplify_sentence(sentence, lexicon_data=lexicon_data)\n",
    "    print(\"Simplified:\", simplified)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
