{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "445de4ff-1e31-4462-9e5d-9c3e8b6abf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emijhang/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "[nltk_data] Downloading package punkt to /Users/emijhang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Download required NLTK data files\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Initialize SpaCy for tokenization and part of speech tagging\n",
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba420a7-c04f-4e58-89b3-328e44dd9f02",
   "metadata": {},
   "source": [
    "## Loading in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f95b9a-60fd-4ed2-8da1-69c75a2f75b9",
   "metadata": {},
   "source": [
    "Data Description from Github:\n",
    "_______________________\n",
    "\n",
    "Word Complexity Lexicon (https://github.com/mounicam/lexical_simplification/tree/master/word_complexity_lexicon)\n",
    "_______________________\n",
    "\n",
    "\n",
    "lexicon.tsv : Each line consists of word and its complexity scores calculated by aggregating over human ratings. \n",
    "              The score belongs to a scale of 1-6, where 1 represents \"very simple\" and 6 represents \"very complex\"\n",
    "\n",
    "lexion_annotations.tsv: Each line consists of a word in the lexicon and its individual ratings from 11 annotators.\n",
    "                        Each rating again belongs to the scale of 1-6. -1 indicates that the annotator did not rate\n",
    "                        the word.\n",
    "                        \n",
    "NOTE: Both the files are tab delimited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c78895-1cf0-40ca-b74d-545ae0893d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_data = pd.read_csv('../WCL_data/lexicon.csv')\n",
    "lexicon_ann = pd.read_csv('../WCL_data/lexicon_annotations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dfe4b0-b130-4ddb-afea-bc313d4242f1",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a0871f9-bc15-4edd-9c5f-1337dd702f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexicon data\n",
      "(15180, 2)\n",
      "            word  rating\n",
      "0            wet  1.5714\n",
      "1          cargo  2.8571\n",
      "2        Arsenal  3.7143\n",
      "3  Manufacturing  3.8333\n",
      "4           East  1.2857\n",
      "Lexicon ann\n",
      "(15180, 12)\n",
      "            word  ann_1  ann_2  ann_3  ann_4  ann_5  ann_6  ann_7  ann_8  \\\n",
      "0            wet     -1      1      1     -1      1      1      2      3   \n",
      "1          cargo     -1     -1      2     -1      4      2      2      4   \n",
      "2        Arsenal      4     -1     -1      4      5     -1      4      3   \n",
      "3  Manufacturing     -1      4      4     -1     -1      3      4      4   \n",
      "4           East     -1      2      1      1      1     -1      1      2   \n",
      "\n",
      "   ann_9  ann_10  ann_11  \n",
      "0     -1       2      -1  \n",
      "1     -1       3       3  \n",
      "2      3      -1       3  \n",
      "3     -1       4      -1  \n",
      "4      1      -1      -1  \n"
     ]
    }
   ],
   "source": [
    "# TODO: \n",
    "# Clean Data\n",
    "# split into train and test\n",
    "# Get dimensions, summary, etc. of data\n",
    "print(\"Lexicon data\")\n",
    "print(lexicon_data.shape)\n",
    "print(lexicon_data.head())\n",
    "\n",
    "print(\"Lexicon ann\")\n",
    "print(lexicon_ann.shape)\n",
    "print(lexicon_ann.head())\n",
    "\n",
    "data = lexicon_data.dropna(subset=[\"word\", \"rating\"])  # Drop rows with NaN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162adc7f-e0a1-4b4e-9d88-12abd3e5d88a",
   "metadata": {},
   "source": [
    "## Vectorizing, Regressor\n",
    "\n",
    "Training a regressor so that for words not present in the vocabulary, we can predict the difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0d1c172-9fed-4f30-9ac8-03ac83bbe423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3.250991774195391\n",
      "R-squared Score: -4.050382118710537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../WCL_regressor.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "X = data[\"word\"].values  # Target words\n",
    "y = data[\"rating\"].values.astype(float)  # Continuous difficulty ratings\n",
    "\n",
    "# Vectorize words\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectors = vectorizer.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectors, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train regressor\n",
    "regressor = RandomForestRegressor()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R-squared Score:\", r2_score(y_test, y_pred))\n",
    "joblib.dump(regressor, \"../WCL_regressor.pkl\")\n",
    "# regressor = joblib.load(\"WCL_regressor.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274093f2-f286-44b1-9e68-9228530ac618",
   "metadata": {},
   "source": [
    "## Simplification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5917d904-d728-4720-a207-e874aebf5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def simplify_sentence(sentence, regressor, vectorizer, word2vec_model, difficulty_threshold=3):\n",
    "    \"\"\"\n",
    "    Simplifies a sentence by replacing difficult words with simpler alternatives.\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): Input sentence to be simplified.\n",
    "        regressor: Trained regressor model for predicting word difficulty.\n",
    "        vectorizer: Trained vectorizer for transforming words into features.\n",
    "        word2vec_model: Trained Word2Vec model for word similarity.\n",
    "        difficulty_threshold (float): Threshold above which words are considered difficult.\n",
    "    \n",
    "    Returns:\n",
    "        str: Simplified sentence.\n",
    "    \"\"\"\n",
    "    # Tokenize the sentence into words\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    simplified_words = []\n",
    "    changed_words = []\n",
    "\n",
    "    for word in words:\n",
    "        # Check if the word exists in the difficulty dictionary (or predict difficulty if not)\n",
    "        vector = vectorizer.transform([word])\n",
    "        if word not in X:\n",
    "            difficulty = regressor.predict(vector)[0]  \n",
    "        else: \n",
    "            difficulty = data[data['word']==word]['rating'].to_numpy()\n",
    "        if difficulty > difficulty_threshold:\n",
    "            try:\n",
    "                similar_words = word2vec_model.wv.most_similar(word, topn=10)\n",
    "                print(similar_words)\n",
    "                hi\n",
    "\n",
    "                for sim_word, _ in similar_words:\n",
    "                    sim_vector = vectorizer.transform([sim_word])\n",
    "                    sim_difficulty = regressor.predict(sim_vector)[0]\n",
    "\n",
    "                    if sim_difficulty <= difficulty:\n",
    "                        simplified_words.append(sim_word) \n",
    "                        changed_words.append((word, sim_word))\n",
    "                        break\n",
    "                    else:\n",
    "                        simplified_words.append(word)probabilties                                                            \n",
    "            except KeyError:\n",
    "                simplified_words.append(word)\n",
    "        else:\n",
    "            simplified_words.append(word)\n",
    "\n",
    "    simplified_sentence = \" \".join(simplified_words)\n",
    "    return simplified_sentence, changed_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad2ed1-5777-45c0-aca4-f0c9d905df1c",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "febf9da5-a1d8-4998-8b92-f054b54faef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: This is a simple sentence.\n",
      "Simplified Sentence: This is a simple sentences .\n",
      "Words Changed: [('sentence', 'sentences')] \n",
      "\n",
      "rouge1: Score(precision=1.0, recall=1.0, fmeasure=1.0)\n",
      "rouge2: Score(precision=1.0, recall=1.0, fmeasure=1.0)\n",
      "rougeL: Score(precision=1.0, recall=1.0, fmeasure=1.0)\n",
      "--------------------------------------------------\n",
      "Original Sentence: Although she was considered smart, she failed all her exams.\n",
      "Simplified Sentence: Although she was regarded smart , she failed all her exams .\n",
      "Words Changed: [('considered', 'regarded')] \n",
      "\n",
      "rouge1: Score(precision=0.9, recall=0.9, fmeasure=0.9)\n",
      "rouge2: Score(precision=0.7777777777777778, recall=0.7777777777777778, fmeasure=0.7777777777777778)\n",
      "rougeL: Score(precision=0.9, recall=0.9, fmeasure=0.9)\n",
      "--------------------------------------------------\n",
      "Original Sentence: Anachronism in historical contexts can be confusing.\n",
      "Simplified Sentence: Anachronism in historial context can be convoluted .\n",
      "Words Changed: [('historical', 'historial'), ('contexts', 'context'), ('confusing', 'convoluted')] \n",
      "\n",
      "rouge1: Score(precision=0.7142857142857143, recall=0.7142857142857143, fmeasure=0.7142857142857143)\n",
      "rouge2: Score(precision=0.5, recall=0.5, fmeasure=0.5)\n",
      "rougeL: Score(precision=0.7142857142857143, recall=0.7142857142857143, fmeasure=0.7142857142857143)\n",
      "--------------------------------------------------\n",
      "Original Sentence: accumulated, thesaurus, differing, terror\n",
      "Simplified Sentence: accumulating , dictionary , varying , terrorism\n",
      "Words Changed: [('accumulated', 'accumulating'), ('thesaurus', 'dictionary'), ('differing', 'varying'), ('terror', 'terrorism')] \n",
      "\n",
      "rouge1: Score(precision=0.5, recall=0.5, fmeasure=0.5)\n",
      "rouge2: Score(precision=0.0, recall=0.0, fmeasure=0.0)\n",
      "rougeL: Score(precision=0.5, recall=0.5, fmeasure=0.5)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "word2vec_model = api.load('word2vec-google-news-300')\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "test_sentences = [\n",
    "    \"This is a simple sentence.\",\n",
    "    \"Although she was considered smart, she failed all her exams.\",\n",
    "    \"Anachronism in historical contexts can be confusing.\",\n",
    "    \"accumulated, thesaurus, differing, terror\"\n",
    "]\n",
    "for sentence in test_sentences:\n",
    "\n",
    "    simplified, changed_words = simplify_sentence(\n",
    "        sentence, \n",
    "        regressor, \n",
    "        vectorizer, \n",
    "        word2vec_model,  \n",
    "        difficulty_threshold=2\n",
    "    )\n",
    "    print(\"Original Sentence:\", sentence)\n",
    "    print(\"Simplified Sentence:\", simplified)\n",
    "    print(\"Words Changed:\", changed_words, \"\\n\")\n",
    "\n",
    "    scores = scorer.score(sentence, simplified)\n",
    "    for key in scores:\n",
    "        print(f'{key}: {scores[key]}')\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd25abf-d2fb-4a76-9b94-5c53f5d9b720",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Testing Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f97f04b-7f08-48b8-b184-c609ac2b2d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset csv (file:///Users/emijhang/.cache/huggingface/datasets/bogdancazan___csv/bogdancazan--wikilarge-text-simplification-6bc5552af2c5d584/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Loading a dataset cached in a LocalFileSystem is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load a dataset for text simplification\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbogdancazan/wikilarge-text-simplification\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/load.py:1810\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1806\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   1807\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1808\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   1809\u001b[0m )\n\u001b[0;32m-> 1810\u001b[0m ds \u001b[38;5;241m=\u001b[39m builder_instance\u001b[38;5;241m.\u001b[39mas_dataset(split\u001b[38;5;241m=\u001b[39msplit, verification_mode\u001b[38;5;241m=\u001b[39mverification_mode, in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory)\n\u001b[1;32m   1811\u001b[0m \u001b[38;5;66;03m# Rename and cast features to match task schema\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/builder.py:1107\u001b[0m, in \u001b[0;36mDatasetBuilder.as_dataset\u001b[0;34m(self, split, run_post_process, verification_mode, ignore_verifications, in_memory)\u001b[0m\n\u001b[1;32m   1105\u001b[0m is_local \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m is_remote_filesystem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs)\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading a dataset cached in a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir):\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1110\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: could not find data in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please make sure to call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuilder.download_and_prepare(), or use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets.load_dataset() before trying to access the Dataset object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Loading a dataset cached in a LocalFileSystem is not supported."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load a dataset for text simplification\n",
    "dataset = load_dataset(\"bogdancazan/wikilarge-text-simplification\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fd61e9c-59bd-4c4c-b9d4-c72649aaa6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Add the task prefix for T5 input format\n",
    "    inputs = [\"simplify: \" + text for text in examples['Normal']]\n",
    "    targets = examples['Simple']\n",
    "    \n",
    "    # Tokenize the inputs and outputs (text pairs)\n",
    "    model_inputs = tokenizer(inputs, padding=\"max_length\", max_length=MAX_LENGTH, truncation=True)\n",
    "    labels = tokenizer(targets, padding=\"max_length\", max_length=MAX_LENGTH, truncation=True)\n",
    "\n",
    "    # Add labels as tokenized targets (this will be used for decoder during training)\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_subset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(800))\n",
    "validation_subset = tokenized_dataset[\"validation\"].shuffle(seed=42).select(range(200))\n",
    "testing_subset = tokenized_dataset[\"test\"].shuffle(seed=42).select(range(150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de6f99ab-d6ee-4a9b-8531-7d3130588059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 20:10, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.504400</td>\n",
       "      <td>0.440592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.358600</td>\n",
       "      <td>0.434567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.7003867316246033, metrics={'train_runtime': 1214.3697, 'train_samples_per_second': 1.318, 'train_steps_per_second': 0.082, 'total_flos': 54136720588800.0, 'train_loss': 0.7003867316246033, 'epoch': 2.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name) \n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=0.001,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# Set up Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_subset,\n",
    "    eval_dataset=validation_subset,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f35d1a9-8c36-46b0-85ac-f81417f84712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate simplified text\n",
    "def simplify_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=50, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "508e4a96-a498-4d84-85aa-dc64ef1ea20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: This is a simple sentence.\n",
      "Simplified: This is a simple sentence.\n",
      "rouge1: Score(precision=1.0, recall=1.0, fmeasure=1.0)\n",
      "rouge2: Score(precision=1.0, recall=1.0, fmeasure=1.0)\n",
      "rougeL: Score(precision=1.0, recall=1.0, fmeasure=1.0)\n",
      "--------------------------------------------------\n",
      "Original: This is an example of a complex sentence that includes technical jargon and unnecessary details, making it harder to understand for a general audience.\n",
      "Simplified: This is an example of a complex sentence that includes technical jargon and unnecessary details.\n",
      "rouge1: Score(precision=1.0, recall=0.625, fmeasure=0.7692307692307693)\n",
      "rouge2: Score(precision=1.0, recall=0.6086956521739131, fmeasure=0.7567567567567568)\n",
      "rougeL: Score(precision=1.0, recall=0.625, fmeasure=0.7692307692307693)\n",
      "--------------------------------------------------\n",
      "Original: Although she was considered smart, she failed all her exams.\n",
      "Simplified: \n",
      "rouge1: Score(precision=0.0, recall=0.0, fmeasure=0.0)\n",
      "rouge2: Score(precision=0.0, recall=0.0, fmeasure=0.0)\n",
      "rougeL: Score(precision=0, recall=0, fmeasure=0)\n",
      "--------------------------------------------------\n",
      "Original: Anachronism in historical contexts can be confusing.\n",
      "Simplified: Anachronism in historical contexts can be confusing.\n",
      "rouge1: Score(precision=1.0, recall=1.0, fmeasure=1.0)\n",
      "rouge2: Score(precision=1.0, recall=1.0, fmeasure=1.0)\n",
      "rougeL: Score(precision=1.0, recall=1.0, fmeasure=1.0)\n",
      "--------------------------------------------------\n",
      "Original: accumulated, thesaurus, differing, terror\n",
      "Simplified: accumulated, thesaurus, differing, terror.\n",
      "rouge1: Score(precision=1.0, recall=1.0, fmeasure=1.0)\n",
      "rouge2: Score(precision=1.0, recall=1.0, fmeasure=1.0)\n",
      "rougeL: Score(precision=1.0, recall=1.0, fmeasure=1.0)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set device to MPS (if available)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def simplify_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs = inputs.to(device)  # Move inputs to the MPS device\n",
    "\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=50, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "test_sentences = [\n",
    "    \"This is a simple sentence.\",\n",
    "    \"This is an example of a complex sentence that includes technical jargon and unnecessary details, making it harder to understand for a general audience.\",\n",
    "    \"Although she was considered smart, she failed all her exams.\",\n",
    "    \"Anachronism in historical contexts can be confusing.\",\n",
    "    \"accumulated, thesaurus, differing, terror\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    simplified = simplify_text(sentence)\n",
    "    print(f\"Original: {sentence}\")\n",
    "    print(f\"Simplified: {simplified}\")\n",
    "\n",
    "    scores = scorer.score(sentence, simplified)\n",
    "    for key in scores:\n",
    "        print(f'{key}: {scores[key]}')\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601960bc-4c1d-486f-9a8d-1438f53b0eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
